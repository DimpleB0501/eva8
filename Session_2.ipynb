{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DimpleB0501/eva8/blob/main/Session_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function # this has to be at the top. A future statement is a directive to the compiler that a particular module should be compiled using syntax or semantics that will be available in a specified future release of Python where the feature becomes standard. The future statement is intended to ease migration to future versions of Python that introduce incompatible changes to the language.\n",
        "import torch # import pytorch \n",
        "import torch.nn as nn # import all the functions that are used in neural networks models. https://pytorch.org/tutorials/beginner/nn_tutorial.html\n",
        "import torch.nn.functional as F #https://pytorch.org/docs/stable/nn.functional.html\n",
        "import torch.optim as optim # Implemented optimization functions. https://pytorch.org/docs/stable/optim.html\n",
        "from torchvision import datasets, transforms # The torchvision package consists of popular datasets, model architectures, and common image transformations for computer vision."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_Cx9q2QFgM7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "4cebeba7-2c5a-4c86-8bf0-6aa5f2dbabce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nclass Net(nn.Module):\\n# https://blog.mlreview.com/a-guide-to-receptive-field-arithmetic-for-convolutional-neural-networks-e0f514068807\\n    def __init__(self):\\n        super(Net, self).__init__()\\n        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)    #input 28x28x1     output 28x28x32  \\t\\n        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)   #input 28x28x32    output 28x28x64  \\n        self.pool1 = nn.MaxPool2d(2, 2)                #input 28x28x64    output 14x14x64\\t\\n        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)  #input 14x14x64    output 14x14x128 \\t\\n        self.conv4 = nn.Conv2d(128, 256, 3, padding=1) #input 14x14x128   output 14x14x256\\t\\n        self.pool2 = nn.MaxPool2d(2, 2)                #input 14x14x256   output 7x7x256\\t\\n        self.conv5 = nn.Conv2d(256, 512, 3)            #input 7x7x256\\t    output 5x5x512  \\t\\n        self.conv6 = nn.Conv2d(512, 1024, 3)           #input 5x5x512     output 3x3x1024\\t  \\n        self.conv7 = nn.Conv2d(1024, 10, 3)            #input 3x3x1024\\t  output 1x1x10\\t\\t \\n\\n    def forward(self, x):\\n        x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\\n        x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\\n        x = F.relu(self.conv6(F.relu(self.conv5(x))))\\n        x = F.relu(self.conv7(x))\\n        x = x.view(-1, 10)\\n        return F.log_softmax(x)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "'''\n",
        "class Net(nn.Module):\n",
        "# https://blog.mlreview.com/a-guide-to-receptive-field-arithmetic-for-convolutional-neural-networks-e0f514068807\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)    #input 28x28x1     output 28x28x32  \t\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)   #input 28x28x32    output 28x28x64  \n",
        "        self.pool1 = nn.MaxPool2d(2, 2)                #input 28x28x64    output 14x14x64\t\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)  #input 14x14x64    output 14x14x128 \t\n",
        "        self.conv4 = nn.Conv2d(128, 256, 3, padding=1) #input 14x14x128   output 14x14x256\t\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)                #input 14x14x256   output 7x7x256\t\n",
        "        self.conv5 = nn.Conv2d(256, 512, 3)            #input 7x7x256\t    output 5x5x512  \t\n",
        "        self.conv6 = nn.Conv2d(512, 1024, 3)           #input 5x5x512     output 3x3x1024\t  \n",
        "        self.conv7 = nn.Conv2d(1024, 10, 3)            #input 3x3x1024\t  output 1x1x10\t\t \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
        "        x = self.pool2(F.relu(self.conv4(F.relu(self.conv3(x)))))\n",
        "        x = F.relu(self.conv6(F.relu(self.conv5(x))))\n",
        "        x = F.relu(self.conv7(x))\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKtoHA8N4iPr"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "# https://blog.mlreview.com/a-guide-to-receptive-field-arithmetic-for-convolutional-neural-networks-e0f514068807\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3)    #input 28x28x1     output 26x26x32  \t\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3)   #input 26x26x32    output 24x24x64  \n",
        "        self.pool1 = nn.MaxPool2d(2, 2)     #input 24x24x64    output 12x12x64\t\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3)  #input 12x12x64    output 10x10x128 \t\n",
        "        self.conv4 = nn.Conv2d(128, 256, 3) #input 10x10x128   output 8x8x256\t\n",
        "        self.conv5 = nn.Conv2d(256, 512, 3) #input 8x8x256   output 6x6x512\t\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)     #input 6x6x512\t\t  output 3x3x512\t\n",
        "        self.conv7 = nn.Conv2d(512, 10, 3)  #input 3x3x1024\t  output 1x1x10\t\t \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.conv2(F.relu(self.conv1(x)))))\n",
        "        x = self.pool2(F.relu(self.conv5(F.relu(self.conv4(F.relu(self.conv3(x)))))))\n",
        "        #x = F.relu(self.conv6(F.relu(self.conv5(x))))\n",
        "        x = F.relu(self.conv7(x))\n",
        "        x = x.view(-1, 10)\n",
        "        return F.log_softmax(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdydjYTZFyi3",
        "outputId": "3f3435f4-78cc-464e-e5fa-218c33ac4a63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.8/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 26, 26]             320\n",
            "            Conv2d-2           [-1, 64, 24, 24]          18,496\n",
            "         MaxPool2d-3           [-1, 64, 12, 12]               0\n",
            "            Conv2d-4          [-1, 128, 10, 10]          73,856\n",
            "            Conv2d-5            [-1, 256, 8, 8]         295,168\n",
            "            Conv2d-6            [-1, 512, 6, 6]       1,180,160\n",
            "         MaxPool2d-7            [-1, 512, 3, 3]               0\n",
            "            Conv2d-8             [-1, 10, 1, 1]          46,090\n",
            "================================================================\n",
            "Total params: 1,614,090\n",
            "Trainable params: 1,614,090\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.92\n",
            "Params size (MB): 6.16\n",
            "Estimated Total Size (MB): 7.08\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b899063f98be>:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available() # check if the system is on cpu or gpu\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\") # select the device as gpu if available \n",
        "model = Net().to(device) # put the convolutional  network to the device \n",
        "# https://towardsdatascience.com/understanding-and-calculating-the-number-of-parameters-in-convolution-neural-networks-cnns-fc88790d530d\n",
        "# 1 conv layer ((m * n * d)+1)* k) i.e. ((shape of width of the filter * shape of height of the filter * number of filters in the previous layer+1)*number of filters)\n",
        "# so conv1 ((3*3*1) + 1) * 32 = 320\n",
        "# conv2 ((3*3*32)+1) * 64 = 18496\n",
        "summary(model, input_size=(1, 28, 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgU0CscF2gI6",
        "outputId": "12d88f41-8d4c-4940-b99e-da2f7a95d219"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchscan in /usr/local/lib/python3.8/dist-packages (0.1.2)\n",
            "Requirement already satisfied: torch<2.0.0,>=1.5.0 in /usr/local/lib/python3.8/dist-packages (from torchscan) (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch<2.0.0,>=1.5.0->torchscan) (4.4.0)\n"
          ]
        }
      ],
      "source": [
        "pip install torchscan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UEGwDuq2jgF",
        "outputId": "08ade534-7561-4ecd-c524-ac929f7fe9de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_________________________________________________________________________\n",
            "Layer      Type         Output Shape         Param #      Receptive field\n",
            "=========================================================================\n",
            "net        Net          (-1, 10)             0            1              \n",
            "├─conv1    Conv2d       (-1, 32, 26, 26)     320          3              \n",
            "├─conv2    Conv2d       (-1, 64, 24, 24)     18,496       5              \n",
            "├─pool1    MaxPool2d    (-1, 64, 12, 12)     0            6              \n",
            "├─conv3    Conv2d       (-1, 128, 10, 10)    73,856       10             \n",
            "├─conv4    Conv2d       (-1, 256, 8, 8)      295,168      14             \n",
            "├─conv5    Conv2d       (-1, 512, 6, 6)      1,180,160    18             \n",
            "├─pool2    MaxPool2d    (-1, 512, 3, 3)      0            20             \n",
            "├─conv7    Conv2d       (-1, 10, 1, 1)       46,090       28             \n",
            "=========================================================================\n",
            "Trainable params: 1,614,090\n",
            "Non-trainable params: 0\n",
            "Total params: 1,614,090\n",
            "-------------------------------------------------------------------------\n",
            "Model size (params + buffers): 6.16 Mb\n",
            "Framework & CUDA overhead: 1071.84 Mb\n",
            "Total RAM usage: 1078.00 Mb\n",
            "-------------------------------------------------------------------------\n",
            "Floating Point Operations on forward: 159.16 MFLOPs\n",
            "Multiply-Accumulations on forward: 79.59 MMACs\n",
            "Direct memory accesses on forward: 81.36 MDMAs\n",
            "_________________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-b899063f98be>:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        }
      ],
      "source": [
        "from torchscan import summary\n",
        "summary(model,(1, 28, 28), receptive_field=True, max_depth=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqTWLaM5GHgH"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1)\n",
        "batch_size = 128 # datasize is 128 while processing it in batches\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader( # load the training and apply transforms like normalization and converting it to a tensor\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,)) # use mean of and std deivation of training set\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,)) \n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm # training models with progress bars\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader) # progress depends on data and batch size\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device) # upload data and labels to gpu (or cpu)\n",
        "        optimizer.zero_grad() # https://pytorch.org/docs/stable/generated/torch.optim.Optimizer.zero_grad.html, optimizer.zero_grad() clears x.grad for every parameter x in the optimizer. It’s important to call this before loss.backward(), otherwise you’ll accumulate the gradients from multiple passes.\n",
        "        output = model(data) # process the data through the models\n",
        "        loss = F.nll_loss(output, target) # calculate the loss\n",
        "        loss.backward() #  computes dloss/dx for every parameter x which has requires_grad=True. These are accumulated into x.grad for every parameter x. In pseudo-code:x.grad += dloss/dx\n",
        "        optimizer.step() # perform parameter update, optimizer.step updates the value of x using the gradient x.grad. For example, the SGD optimizer performs:x += -lr * x.grad\n",
        "\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMWbLWO6FuHb",
        "outputId": "8ad623c4-a44a-4077-9470-68922df85a9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]<ipython-input-3-b899063f98be>:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n",
            "loss=0.748197615146637 batch_id=468: 100%|██████████| 469/469 [00:18<00:00, 25.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.7501, Accuracy: 6898/10000 (69%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model = Net().to(device) # put the model to device\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9) # using sgd optimizer https://pytorch.org/docs/stable/generated/torch.optim.SGD.html\n",
        "\n",
        "for epoch in range(1, 2): # number of times the train needs to be performed\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "So5uk4EkHW6R"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}