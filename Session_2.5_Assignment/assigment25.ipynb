{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+htsmVhp8So0MHbQgEgUH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DimpleB0501/eva8/blob/main/Session_2.5_Assignment/assigment25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST dataset train and test"
      ],
      "metadata": {
        "id": "L5JhFQGxbfxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsHBhPacblK6",
        "outputId": "e694cb81-395b-4ed0-d590-a45a53eb4597"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision # provide access to datasets, models, transforms, utils, etc\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "iOaCUQu-gCE9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Pytorch version:\", torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqBa20zugGQJ",
        "outputId": "f07e7daa-663d-40b0-ca53-6d22474f098b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pytorch version: 1.13.0+cu116\n",
            "Pytorch version: 1.13.0+cu116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select GPU mode"
      ],
      "metadata": {
        "id": "iUlzppVygH-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU available\n",
        "if torch.cuda.is_available():\n",
        "  print (\"On GPU\")\n",
        "else :\n",
        "  print (\"No GPU available\")\n",
        "     \n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35ZsFIgSgGqd",
        "outputId": "66a466a8-10c7-45f4-efce-49946fc8ba1e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU available\n",
            "No GPU available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a custom dataset"
      ],
      "metadata": {
        "id": "2NFm5u_hj2eO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "E5OqobnXnPQ-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist =  torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform = transforms.Compose([\n",
        "          transforms.ToTensor()\n",
        "    ])\n",
        ")"
      ],
      "metadata": {
        "id": "YRaGNS6zkVy6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One value in dataset"
      ],
      "metadata": {
        "id": "o-sRRlA76-6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(mnist, batch_size = 1, shuffle=True)"
      ],
      "metadata": {
        "id": "Pqu2nE6qwACd"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating custom dataset\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    batch = next(iter(train_loader))\n",
        "    self.data = batch[0]\n",
        "    self.label = batch[1]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image = self.data[index]\n",
        "    label = self.label[index]\n",
        "    z = torch.tensor(random.randint(0, 9))\n",
        "    #z_oh = one_hot (z)\n",
        "    return image, label, z, label+z\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "myData = MyDataset()\n",
        "\n",
        "for m in myData:\n",
        "  print (\"label:\", m[1])\n",
        "  print (\"Random number generated:\", m[2])\n",
        "  print (\"Addition(randnum+image):\", m[3])\n",
        "  print (\"Image:\")\n",
        "  grid = torchvision.utils.make_grid(m[0], nrow=10)\n",
        "  plt.figure(figsize=(5,5))\n",
        "  plt.imshow(np.transpose(grid, (1,2,0)))\n",
        "\n",
        "#print (\"here\", len(myData))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 762
        },
        "id": "xC0Qq4sDxf-s",
        "outputId": "c7fc5607-4e0f-4f35-c39d-a30314ec960c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label: tensor(8)\n",
            "Random number generated: tensor(6)\n",
            "Addition(randnum+image): tensor(14)\n",
            "Image:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label: tensor(7)\n",
            "Random number generated: tensor(7)\n",
            "Addition(randnum+image): tensor(14)\n",
            "Image:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom dataset"
      ],
      "metadata": {
        "id": "T6mJN63S7SdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot encoding\n",
        "def one_hot (integer):\n",
        "  rand_number = torch.zeros(28, 28)\n",
        "  rand_number[:,] =1\n",
        "  one_hot=torch.zeros(28)\n",
        "  one_hot[integer]=1\n",
        "  rand_number = rand_number * one_hot\n",
        "  #print (rand_number)\n",
        "  #print (rand_number.shape)\n",
        "  rand_number = rand_number.unsqueeze(dim=0)\n",
        "  return rand_number"
      ],
      "metadata": {
        "id": "5gmfjyChnHgG"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_label(label):\n",
        "  rand_number = torch.zeros(1, 20)\n",
        "  rand_number[:,] =1\n",
        "  one_hot=torch.zeros(20)\n",
        "  one_hot[label]=1\n",
        "  rand_number = rand_number * one_hot\n",
        "  #print (rand_number)\n",
        "  rand_number = rand_number.squeeze(dim=0)\n",
        "  return rand_number"
      ],
      "metadata": {
        "id": "VkFjsNpvwFUS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, batch_size = 50000):\n",
        "    train_loader = torch.utils.data.DataLoader(mnist, batch_size = batch_size, shuffle=True)\n",
        "    batch = next(iter(train_loader))\n",
        "    self.data = batch[0]\n",
        "    self.label = batch[1]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image = self.data[index]\n",
        "    label = self.label[index]\n",
        "    z = torch.tensor(random.randint(0, 9))\n",
        "    z_oh = one_hot(z)\n",
        "    label_add = one_hot_label(label+z)\n",
        "    return image, label, z_oh, label_add\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "'''\n",
        "for m in data:\n",
        "  print (\"label:\", m[1])\n",
        "  print (\"Random number generated:\", m[2])\n",
        "  print (\"Addition(randnum+image):\", m[3])\n",
        "  print (\"Image:\")\n",
        "  grid = torchvision.utils.make_grid(m[0], nrow=10)\n",
        "  plt.figure(figsize=(2,2))\n",
        "  plt.imshow(np.transpose(grid, (1,2,0)))\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "akM5_DtX93Sp",
        "outputId": "12648744-1123-49b5-84f9-345f5a78cbae"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfor m in data:\\n  print (\"label:\", m[1])\\n  print (\"Random number generated:\", m[2])\\n  print (\"Addition(randnum+image):\", m[3])\\n  print (\"Image:\")\\n  grid = torchvision.utils.make_grid(m[0], nrow=10)\\n  plt.figure(figsize=(2,2))\\n  plt.imshow(np.transpose(grid, (1,2,0)))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfor m in data:\\n  print (\"label:\", m[1])\\n  print (\"Random number generated:\", m[2])\\n  print (\"Addition(randnum+image):\", m[3])\\n  print (\"Image:\")\\n  grid = torchvision.utils.make_grid(m[0], nrow=10)\\n  plt.figure(figsize=(2,2))\\n  plt.imshow(np.transpose(grid, (1,2,0)))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a model"
      ],
      "metadata": {
        "id": "EOAJH-7yhmkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "6Da9Luvil2PF"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(torch.nn.Module):\n",
        "     \n",
        "  def __init__(self):   \n",
        "        super(LeNet, self).__init__()\n",
        "        # Convolution (In LeNet, 32x32 images are given as input. Hence padding of 2 is done below)\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "        # Max-pooling\n",
        "        self.max_pool_1 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "        # Convolution\n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0, bias=True)\n",
        "        # Max-pooling\n",
        "        self.max_pool_2 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc1 = torch.nn.Linear(16*5*5, 120)   # convert matrix with 16*5*5 (= 400) features to a matrix of 120 features (columns)\n",
        "        self.fc2 = torch.nn.Linear(120, 84)       # convert matrix with 120 features to a matrix of 84 features (columns)\n",
        "        self.fc3 = torch.nn.Linear(84, 10)        # convert matrix with 84 features to a matrix of 10 features (columns)\n",
        "        self.fc4 = torch.nn.Linear(84, 19)        # for addition of MNIST prediction with random number\n",
        "\n",
        "  def forward(self, x, y):\n",
        "        # convolve, then perform ReLU non-linearity\n",
        "        x = torch.nn.functional.relu(self.conv1(x))  \n",
        "        y = torch.nn.functional.relu(self.conv1(y)) \n",
        "        # max-pooling with 2x2 grid\n",
        "        x = self.max_pool_1(x)\n",
        "        y = self.max_pool_1(y)\n",
        "\n",
        "        # convolve, then perform ReLU non-linearity\n",
        "        x = torch.nn.functional.relu(self.conv2(x))\n",
        "        y = torch.nn.functional.relu(self.conv2(y))\n",
        "        # max-pooling with 2x2 grid\n",
        "        x = self.max_pool_2(x)\n",
        "        y = self.max_pool_2(y)\n",
        "\n",
        "        # first flatten 'max_pool_2_out' to contain 16*5*5 columns\n",
        "        # read through https://stackoverflow.com/a/42482819/7551231\n",
        "        x = x.view(-1, 16*5*5)\n",
        "        y = y.view(-1, 16*5*5)\n",
        "        \n",
        "        z = torch.cat((x,y), dim=0)\n",
        "        z = z.resize(size = (250,400))\n",
        "        #x = x.view(x.size(0), -1)\n",
        "        # FC-1, then perform ReLU non-linearity\n",
        "        x = torch.nn.functional.relu(self.fc1(x))\n",
        "        z = torch.nn.functional.relu(self.fc1(z))\n",
        "        # FC-2, then perform ReLU non-linearity\n",
        "        x = torch.nn.functional.relu(self.fc2(x))\n",
        "        z = torch.nn.functional.relu(self.fc2(z))\n",
        "        # FC-3\n",
        "        x = self.fc3(x)\n",
        "        z = self.fc4(z)\n",
        "        return x, z"
      ],
      "metadata": {
        "id": "xKt_WWQHh54q"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LeNet()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_KhMEJBiWCQ",
        "outputId": "7bc19597-828a-4a2a-c2e2-f64728436c0d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LeNet(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (max_pool_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (max_pool_2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              "  (fc4): Linear(in_features=84, out_features=19, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LeNet(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (max_pool_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (max_pool_2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              "  (fc4): Linear(in_features=84, out_features=19, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model"
      ],
      "metadata": {
        "id": "kdnKTFoEif4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_num_correct(preds, labels):\n",
        "  return preds.argmax(dim=1).eq(labels).sum().item()"
      ],
      "metadata": {
        "id": "T3SGPM8bm6CO"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = CustomDataset(len(mnist)) # 256 is the batch size\n",
        "#print (len(data))\n",
        "loader = torch.utils.data.DataLoader(data, batch_size=250)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(10):\n",
        "  total_loss_1 = 0\n",
        "  total_correct_1 = 0\n",
        "  total_loss_2 = 0\n",
        "  total_correct_2 = 0\n",
        "  for images, labels, rd, rl in loader: # Get Batch\n",
        "      #print (images.size(), labels.size(), rd.size(), rl.size())\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      rd = rd.to(device)\n",
        "      rl = rl.to(device)\n",
        "\n",
        "      preds1, preds2 = model(images, rd) # Pass Batch of images and one hot encoded random number\n",
        "\n",
        "      loss1 = F.cross_entropy(preds1, labels) # Calculate Loss1\n",
        "      #loss2 = F.cross_entropy(preds2, rl) # Calculate Loss2\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      loss1.backward() # Calculate Gradients\n",
        "      #loss2.backward() # Calculate Gradients\n",
        "\n",
        "      optimizer.step() # Update Weights\n",
        "\n",
        "      total_loss_1 += loss1.item()\n",
        "      total_correct_1 += get_num_correct(preds1, labels)\n",
        "\n",
        "      #total_loss_2 += loss2.item()\n",
        "      #total_correct_2 += get_num_correct(preds2, rl)\n",
        "\n",
        "  print(\n",
        "      \"epoch:\", epoch, \"\\n\",\n",
        "      \"MNIST-LENET Architecture: { \"\n",
        "      #\"total_correct:\", total_correct/len(train_set)*100, \n",
        "      \"accuracy(percentage):\", total_correct_1/len(mnist)*100,\n",
        "      #\"loss:\", total_loss/len(train_loader)\n",
        "      \"loss:\", total_loss_1,\"}\\n\"\n",
        "      #\"MNIST+RAND_NO: { \"\n",
        "      #\"total_correct:\", total_correct/len(train_set)*100, \n",
        "      #\"accuracy(percentage):\", total_correct_2/len(mnist)*100,\n",
        "      #\"loss:\", total_loss/len(train_loader)\n",
        "      #\"loss:\", total_loss_2,\"}\"\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ABc9gcm0lLbM",
        "outputId": "d61f5262-4ac8-49e6-f33f-e56f74881a0e"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 \n",
            " MNIST-LENET Architecture: { accuracy(percentage): 91.23833333333333 loss: 64.21041417866945 }\n",
            "\n",
            "epoch: 1 \n",
            " MNIST-LENET Architecture: { accuracy(percentage): 98.15666666666667 loss: 14.461751515045762 }\n",
            "\n",
            "epoch: 2 \n",
            " MNIST-LENET Architecture: { accuracy(percentage): 98.495 loss: 11.667620039545 }\n",
            "\n",
            "epoch: 3 \n",
            " MNIST-LENET Architecture: { accuracy(percentage): 98.80499999999999 loss: 9.635999154532328 }\n",
            "\n",
            "epoch: 4 \n",
            " MNIST-LENET Architecture: { accuracy(percentage): 98.82 loss: 9.401506769121625 }\n",
            "\n",
            "epoch: 5 \n",
            " MNIST-LENET Architecture: { accuracy(percentage): 98.85166666666667 loss: 9.031897851033136 }\n",
            "\n",
            "epoch: 6 \n",
            " MNIST-LENET Architecture: { accuracy(percentage): 98.965 loss: 8.037672426202334 }\n",
            "\n",
            "epoch: 7 \n",
            " MNIST-LENET Architecture: { accuracy(percentage): 99.03833333333333 loss: 7.503787316614762 }\n",
            "\n",
            "epoch: 8 \n",
            " MNIST-LENET Architecture: { accuracy(percentage): 98.965 loss: 8.493911075405777 }\n",
            "\n",
            "epoch: 9 \n",
            " MNIST-LENET Architecture: { accuracy(percentage): 99.11 loss: 7.195050414302386 }\n",
            "\n",
            "epoch: 0 \n",
            " MNIST-LENET Architecture: { accuracy(percentage): 92.53166666666667 loss: 55.706996159628034 }\n",
            "\n",
            "epoch: 1 \n",
            " MNIST-LENET Architecture: { accuracy(percentage): 97.90333333333334 loss: 15.931711880024523 }\n",
            "\n",
            "epoch: 2 \n",
            " MNIST-LENET Architecture: { accuracy(percentage): 98.46833333333333 loss: 12.075446115108207 }\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-9b1ec62b1d54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mtotal_loss_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mtotal_correct_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Get Batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0;31m#print (images.size(), labels.size(), rd.size(), rl.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-5d637a51b779>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mz_oh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mlabel_add\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_oh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_add\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-380ca3cf91cc>\u001b[0m in \u001b[0;36mone_hot\u001b[0;34m(integer)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# one hot encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mone_hot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mrand_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mrand_number\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mone_hot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}