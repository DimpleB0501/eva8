{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGxakdZ2Uw86yUEpsWOKmR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DimpleB0501/eva8/blob/main/Session_2.5_Assignment/assigment25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST dataset train and test"
      ],
      "metadata": {
        "id": "L5JhFQGxbfxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsHBhPacblK6",
        "outputId": "6070e6b8-e119-44b0-fe6d-246a5fb2c9aa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision # provide access to datasets, models, transforms, utils, etc\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "iOaCUQu-gCE9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Pytorch version:\", torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqBa20zugGQJ",
        "outputId": "caf07029-cbb1-4658-a346-2e383bce0733"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pytorch version: 1.13.0+cu116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select GPU mode"
      ],
      "metadata": {
        "id": "iUlzppVygH-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU available\n",
        "if torch.cuda.is_available():\n",
        "  print (\"On GPU\")\n",
        "else :\n",
        "  print (\"No GPU available\")\n",
        "     \n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35ZsFIgSgGqd",
        "outputId": "82d04423-c0a8-408f-f3c6-df5bba6e675f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a custom dataset"
      ],
      "metadata": {
        "id": "2NFm5u_hj2eO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "E5OqobnXnPQ-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist =  torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform = transforms.Compose([\n",
        "          transforms.ToTensor()\n",
        "    ])\n",
        ")"
      ],
      "metadata": {
        "id": "YRaGNS6zkVy6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One value in dataset"
      ],
      "metadata": {
        "id": "o-sRRlA76-6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(mnist, batch_size = 1, shuffle=True)"
      ],
      "metadata": {
        "id": "Pqu2nE6qwACd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating custom dataset\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    batch = next(iter(train_loader))\n",
        "    self.data = batch[0]\n",
        "    self.label = batch[1]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image = self.data[index]\n",
        "    label = self.label[index]\n",
        "    z = torch.tensor(random.randint(0, 9))\n",
        "    #z_oh = one_hot (z)\n",
        "    #return image, label, z_oh, label+z\n",
        "    return image, label, z, label+z\n",
        "   \n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "myData = MyDataset()\n",
        "\n",
        "for m in myData:\n",
        "  print (\"label:\", m[1])\n",
        "  print (\"Random number generated:\", m[2])\n",
        "  print (\"Addition(randnum+image):\", m[3])\n",
        "  print (\"Image:\")\n",
        "  grid = torchvision.utils.make_grid(m[0], nrow=10)\n",
        "  plt.figure(figsize=(5,5))\n",
        "  plt.imshow(np.transpose(grid, (1,2,0)))\n",
        "\n",
        "#print (\"here\", len(myData))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "xC0Qq4sDxf-s",
        "outputId": "1ad4107d-58c4-4ac9-ef67-d8ecbda4ddb5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label: tensor(2)\n",
            "Random number generated: tensor(3)\n",
            "Addition(randnum+image): tensor(5)\n",
            "Image:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom dataset"
      ],
      "metadata": {
        "id": "T6mJN63S7SdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot encoding\n",
        "def one_hot (integer):\n",
        "  rand_number = torch.zeros(28, 28)\n",
        "  rand_number[:,] =1\n",
        "  one_hot=torch.zeros(28)\n",
        "  one_hot[integer]=1\n",
        "  rand_number = rand_number * one_hot\n",
        "  #print (rand_number)\n",
        "  #print (rand_number.shape)\n",
        "  rand_number = rand_number.unsqueeze(dim=0)\n",
        "  return rand_number"
      ],
      "metadata": {
        "id": "5gmfjyChnHgG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_label(label):\n",
        "  rand_number = torch.zeros(1, 20)\n",
        "  rand_number[:,] =1\n",
        "  one_hot=torch.zeros(20)\n",
        "  one_hot[label]=1\n",
        "  rand_number = rand_number * one_hot\n",
        "  #print (rand_number)\n",
        "  rand_number = rand_number.squeeze(dim=0)\n",
        "  return rand_number"
      ],
      "metadata": {
        "id": "VkFjsNpvwFUS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, batch_size = 50000):\n",
        "    train_loader = torch.utils.data.DataLoader(mnist, batch_size = batch_size, shuffle=True)\n",
        "    batch = next(iter(train_loader))\n",
        "    self.data = batch[0]\n",
        "    self.label = batch[1]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image = self.data[index]\n",
        "    label = self.label[index]\n",
        "    z = torch.tensor(random.randint(0, 9))\n",
        "    z_oh = one_hot(z)\n",
        "    label_add = one_hot_label(label+z)\n",
        "    return image, label, z_oh, label_add\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "'''\n",
        "for m in data:\n",
        "  print (\"label:\", m[1])\n",
        "  print (\"Random number generated:\", m[2])\n",
        "  print (\"Addition(randnum+image):\", m[3])\n",
        "  print (\"Image:\")\n",
        "  grid = torchvision.utils.make_grid(m[0], nrow=10)\n",
        "  plt.figure(figsize=(2,2))\n",
        "  plt.imshow(np.transpose(grid, (1,2,0)))\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "akM5_DtX93Sp",
        "outputId": "0255daf7-23ec-4048-8bb7-f44eaa5bd7ee"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfor m in data:\\n  print (\"label:\", m[1])\\n  print (\"Random number generated:\", m[2])\\n  print (\"Addition(randnum+image):\", m[3])\\n  print (\"Image:\")\\n  grid = torchvision.utils.make_grid(m[0], nrow=10)\\n  plt.figure(figsize=(2,2))\\n  plt.imshow(np.transpose(grid, (1,2,0)))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a model"
      ],
      "metadata": {
        "id": "EOAJH-7yhmkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "6Da9Luvil2PF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(torch.nn.Module):\n",
        "     \n",
        "  def __init__(self):   \n",
        "        super(LeNet, self).__init__()\n",
        "        # Convolution (In LeNet, 32x32 images are given as input. Hence padding of 2 is done below)\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "        # Max-pooling\n",
        "        self.max_pool_1 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "        # Convolution\n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0, bias=True)\n",
        "        # Max-pooling\n",
        "        self.max_pool_2 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc1 = torch.nn.Linear(16*5*5, 120)   # convert matrix with 16*5*5 (= 400) features to a matrix of 120 features (columns)\n",
        "        self.fc2 = torch.nn.Linear(120, 84)       # convert matrix with 120 features to a matrix of 84 features (columns)\n",
        "        self.fc3 = torch.nn.Linear(84, 10)        # convert matrix with 84 features to a matrix of 10 features (columns)\n",
        "        self.fc4 = torch.nn.Linear(84, 19)        # for addition of MNIST prediction with random number\n",
        "\n",
        "  def forward(self, x, y):\n",
        "        # convolve, then perform ReLU non-linearity\n",
        "        x = torch.nn.functional.relu(self.conv1(x))  \n",
        "        y = torch.nn.functional.relu(self.conv1(y)) \n",
        "        # max-pooling with 2x2 grid\n",
        "        x = self.max_pool_1(x)\n",
        "        y = self.max_pool_1(y)\n",
        "\n",
        "        # convolve, then perform ReLU non-linearity\n",
        "        x = torch.nn.functional.relu(self.conv2(x))\n",
        "        y = torch.nn.functional.relu(self.conv2(y))\n",
        "        # max-pooling with 2x2 grid\n",
        "        x = self.max_pool_2(x)\n",
        "        y = self.max_pool_2(y)\n",
        "\n",
        "        # first flatten 'max_pool_2_out' to contain 16*5*5 columns\n",
        "        # read through https://stackoverflow.com/a/42482819/7551231\n",
        "        x = x.view(-1, 16*5*5)\n",
        "        y = y.view(-1, 16*5*5)\n",
        "        \n",
        "        z = torch.cat((x,y), 0)\n",
        "\n",
        "        #print (z.shape)\n",
        "        # FC-1, then perform ReLU non-linearity\n",
        "        x = torch.nn.functional.relu(self.fc1(x))\n",
        "        z = torch.nn.functional.relu(self.fc1(z))\n",
        "        # FC-2, then perform ReLU non-linearity\n",
        "        x = torch.nn.functional.relu(self.fc2(x))\n",
        "        z = torch.nn.functional.relu(self.fc2(z))\n",
        "        # FC-3\n",
        "        x = self.fc3(x)\n",
        "        z = self.fc4(z)\n",
        "        return x, z"
      ],
      "metadata": {
        "id": "xKt_WWQHh54q"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LeNet()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_KhMEJBiWCQ",
        "outputId": "fa2d34c7-dafa-4df7-bca6-18d27f092f4f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LeNet(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (max_pool_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (max_pool_2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              "  (fc4): Linear(in_features=84, out_features=19, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model"
      ],
      "metadata": {
        "id": "kdnKTFoEif4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_num_correct(preds, labels):\n",
        "  return preds.argmax(dim=1).eq(labels).sum().item()"
      ],
      "metadata": {
        "id": "T3SGPM8bm6CO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = CustomDataset(len(mnist)) # 256 is the batch size\n",
        "#print (len(data))\n",
        "loader = torch.utils.data.DataLoader(data, batch_size=250)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(10):\n",
        "  total_loss_1 = 0\n",
        "  total_correct_1 = 0\n",
        "  total_loss_2 = 0\n",
        "  total_correct_2 = 0\n",
        "  for images, labels, rd, rl in loader: # Get Batch\n",
        "      #print (images.size(), labels.size(), rd.size(), rl.size())\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      rd = rd.to(device)\n",
        "      rl = rl.to(device)\n",
        "\n",
        "      preds1, preds2 = model(images, rd) # Pass Batch of images and one hot encoded random number\n",
        "\n",
        "      loss1 = F.cross_entropy(preds1, labels) # Calculate Loss1\n",
        "      #loss2 = F.cross_entropy(preds2, rl) # Calculate Loss2\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      loss1.backward() # Calculate Gradients\n",
        "      #loss2.backward() # Calculate Gradients\n",
        "\n",
        "      optimizer.step() # Update Weights\n",
        "\n",
        "      total_loss_1 += loss1.item()\n",
        "      total_correct_1 += get_num_correct(preds1, labels)\n",
        "\n",
        "      #total_loss_2 += loss2.item()\n",
        "      #total_correct_2 += get_num_correct(preds2, rl)\n",
        "\n",
        "  print(\n",
        "      \"epoch:\", epoch, \"\\n\",\n",
        "      \"MNIST-LENET Architecture: { \"\n",
        "      #\"total_correct:\", total_correct/len(train_set)*100, \n",
        "      \"accuracy(percentage):\", total_correct_1/len(mnist)*100,\n",
        "      #\"loss:\", total_loss/len(train_loader)\n",
        "      \"loss:\", total_loss_1,\"}\\n\"\n",
        "      #\"MNIST+RAND_NO: { \"\n",
        "      #\"total_correct:\", total_correct/len(train_set)*100, \n",
        "      #\"accuracy(percentage):\", total_correct_2/len(mnist)*100,\n",
        "      #\"loss:\", total_loss/len(train_loader)\n",
        "      #\"loss:\", total_loss_2,\"}\"\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABc9gcm0lLbM",
        "outputId": "1e556560-e356-4df3-eb67-e8e6332fa808"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 \n",
            " MNIST-LENET Architecture: { accuracy(percentage): 91.60000000000001 loss: 61.30733905173838 }\n",
            "\n",
            "epoch: 1 \n",
            " MNIST-LENET Architecture: { accuracy(percentage): 97.77 loss: 17.690157397650182 }\n",
            "\n",
            "epoch: 2 \n",
            " MNIST-LENET Architecture: { accuracy(percentage): 98.29666666666667 loss: 13.126036568544805 }\n",
            "\n",
            "epoch: 3 \n",
            " MNIST-LENET Architecture: { accuracy(percentage): 98.66666666666667 loss: 10.58143703918904 }\n",
            "\n",
            "epoch: 4 \n",
            " MNIST-LENET Architecture: { accuracy(percentage): 98.715 loss: 10.153607407351956 }\n",
            "\n",
            "epoch: 5 \n",
            " MNIST-LENET Architecture: { accuracy(percentage): 98.92833333333333 loss: 8.544234918430448 }\n",
            "\n",
            "epoch: 6 \n",
            " MNIST-LENET Architecture: { accuracy(percentage): 98.94666666666667 loss: 8.269532244943548 }\n",
            "\n",
            "epoch: 7 \n",
            " MNIST-LENET Architecture: { accuracy(percentage): 98.99166666666666 loss: 8.221567357133608 }\n",
            "\n",
            "epoch: 8 \n",
            " MNIST-LENET Architecture: { accuracy(percentage): 98.965 loss: 8.755280618555844 }\n",
            "\n",
            "epoch: 9 \n",
            " MNIST-LENET Architecture: { accuracy(percentage): 98.99666666666667 loss: 8.153208956238814 }\n",
            "\n"
          ]
        }
      ]
    }
  ]
}