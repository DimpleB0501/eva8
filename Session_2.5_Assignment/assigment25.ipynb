{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNNv7IKQc94zJ3avPrryzu1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DimpleB0501/eva8/blob/main/Session_2.5_Assignment/assigment25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST dataset train and test"
      ],
      "metadata": {
        "id": "L5JhFQGxbfxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsHBhPacblK6",
        "outputId": "b473f3b7-d273-4e54-fb71-92186e0341a7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision # provide access to datasets, models, transforms, utils, etc\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "iOaCUQu-gCE9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Pytorch version:\", torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqBa20zugGQJ",
        "outputId": "a78ac1ad-ce24-49e8-c985-e5caa0c8133d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pytorch version: 1.13.0+cu116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select GPU mode"
      ],
      "metadata": {
        "id": "iUlzppVygH-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU available\n",
        "if torch.cuda.is_available():\n",
        "  print (\"On GPU\")\n",
        "else :\n",
        "  print (\"No GPU available\")\n",
        "     \n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35ZsFIgSgGqd",
        "outputId": "4ad04c70-a24f-4711-9129-272fa7000b52"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a custom dataset"
      ],
      "metadata": {
        "id": "2NFm5u_hj2eO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "E5OqobnXnPQ-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist =  torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform = transforms.Compose([\n",
        "          transforms.ToTensor()\n",
        "    ])\n",
        ")"
      ],
      "metadata": {
        "id": "YRaGNS6zkVy6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One value in dataset"
      ],
      "metadata": {
        "id": "o-sRRlA76-6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(mnist, batch_size = 1, shuffle=True)"
      ],
      "metadata": {
        "id": "Pqu2nE6qwACd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating custom dataset\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    batch = next(iter(train_loader))\n",
        "    self.data = batch[0]\n",
        "    self.label = batch[1]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image = self.data[index]\n",
        "    label = self.label[index]\n",
        "    z = torch.tensor(random.randint(0, 9))\n",
        "    #z_oh = one_hot (z)\n",
        "    #return image, label, z_oh, label+z\n",
        "    return image, label, z, label+z\n",
        "   \n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "myData = MyDataset()\n",
        "\n",
        "for m in myData:\n",
        "  print (\"label:\", m[1])\n",
        "  print (\"Random number generated:\", m[2])\n",
        "  print (\"Addition(randnum+image):\", m[3])\n",
        "  print (\"Image:\")\n",
        "  grid = torchvision.utils.make_grid(m[0], nrow=10)\n",
        "  plt.figure(figsize=(5,5))\n",
        "  plt.imshow(np.transpose(grid, (1,2,0)))\n",
        "\n",
        "#print (\"here\", len(myData))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "xC0Qq4sDxf-s",
        "outputId": "06cc9bc0-77fd-459e-f2ce-aeeb0fa70d27"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label: tensor(4)\n",
            "Random number generated: tensor(4)\n",
            "Addition(randnum+image): tensor(8)\n",
            "Image:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom dataset"
      ],
      "metadata": {
        "id": "T6mJN63S7SdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot encoding\n",
        "def one_hot (integer):\n",
        "  rand_number = torch.zeros(28, 28)\n",
        "  rand_number[:,] =1\n",
        "  one_hot=torch.zeros(28)\n",
        "  one_hot[integer]=1\n",
        "  rand_number = rand_number * one_hot\n",
        "  #print (rand_number)\n",
        "  #print (rand_number.shape)\n",
        "  rand_number = rand_number.unsqueeze(dim=0)\n",
        "  return rand_number"
      ],
      "metadata": {
        "id": "5gmfjyChnHgG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_label(label):\n",
        "  rand_number = torch.zeros(1, 20)\n",
        "  rand_number[:,] =1\n",
        "  one_hot=torch.zeros(20)\n",
        "  one_hot[label]=1\n",
        "  rand_number = rand_number * one_hot\n",
        "  #print (rand_number)\n",
        "  rand_number = rand_number.squeeze(dim=0)\n",
        "  return rand_number"
      ],
      "metadata": {
        "id": "VkFjsNpvwFUS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, batch_size = 50000):\n",
        "    train_loader = torch.utils.data.DataLoader(mnist, batch_size = batch_size, shuffle=True)\n",
        "    batch = next(iter(train_loader))\n",
        "    self.data = batch[0]\n",
        "    self.label = batch[1]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image = self.data[index]\n",
        "    label = self.label[index]\n",
        "    z = torch.tensor(random.randint(0, 9))\n",
        "    z_oh = one_hot(z)\n",
        "    #label_add = one_hot_label(label+z)\n",
        "    #return image, label, z_oh, label_add\n",
        "    return image, label, z_oh, label+z\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "'''\n",
        "for m in data:\n",
        "  print (\"label:\", m[1])\n",
        "  print (\"Random number generated:\", m[2])\n",
        "  print (\"Addition(randnum+image):\", m[3])\n",
        "  print (\"Image:\")\n",
        "  grid = torchvision.utils.make_grid(m[0], nrow=10)\n",
        "  plt.figure(figsize=(2,2))\n",
        "  plt.imshow(np.transpose(grid, (1,2,0)))\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "akM5_DtX93Sp",
        "outputId": "f7298dbc-2b9e-4831-e720-63111a86abbe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfor m in data:\\n  print (\"label:\", m[1])\\n  print (\"Random number generated:\", m[2])\\n  print (\"Addition(randnum+image):\", m[3])\\n  print (\"Image:\")\\n  grid = torchvision.utils.make_grid(m[0], nrow=10)\\n  plt.figure(figsize=(2,2))\\n  plt.imshow(np.transpose(grid, (1,2,0)))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model addition\n"
      ],
      "metadata": {
        "id": "kJYOorjtE1Bv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self,x):\n",
        "        N,_,_,_ = x.size()\n",
        "        return x.view(N,-1)"
      ],
      "metadata": {
        "id": "wwjlE9UZE5Vx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=16,kernel_size=5,stride=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16,out_channels=32,kernel_size=5,stride=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.bn1  = nn.BatchNorm2d(num_features=16)\n",
        "        self.bn2   = nn.BatchNorm2d(num_features=32)\n",
        "        self.bn3   = nn.BatchNorm2d(num_features=64)\n",
        "        self.mp   = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "        self.do   = nn.Dropout2d(p=0.5)\n",
        "        self.l1   =  nn.Linear(128,1024)\n",
        "        self.l2   =  nn.Linear(1024,19)\n",
        "\n",
        "        self.l3 = nn.Linear(64, 1024)\n",
        "        self.l4 = nn.Linear(1024, 10)\n",
        "        \n",
        "    def forward(self, x , y):\n",
        "        x = self.conv_layers1(x)\n",
        "        y = self.conv_layers1(y)\n",
        "        x = self.conv_layers2(x)\n",
        "        y = self.conv_layers2(y)\n",
        "        x = self.conv_layers3(x)\n",
        "        y = self.conv_layers3(y)\n",
        "        N ,_,_,_ = x.size()\n",
        "        x = x.view(N,-1)\n",
        "        #print (\"value_check:\", N)\n",
        "        y = y.view(N,-1)\n",
        "        #z = self.conv_layers2(x + y)\n",
        "        z = torch.cat((x,y),1)\n",
        "        #z = z.view(N,-1)\n",
        "        #print(z.size())\n",
        "        z = self.l1(z)\n",
        "        z = self.relu(z)\n",
        "        z = self.l2(z)\n",
        "\n",
        "        x = self.l3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.l4(x)\n",
        "        return x, z\n",
        "    \n",
        "    def conv_layers1(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.mp(x)\n",
        "        return x\n",
        "    \n",
        "    def conv_layers2(self, x):\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.mp(x)\n",
        "        return x\n",
        "    \n",
        "    def conv_layers3(self, x):\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.mp(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ZGtqdjsYeZJU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-NnwcGMFPeD",
        "outputId": "85a6ea40-5130-498d-d98d-dec14a9b3e40"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (do): Dropout2d(p=0.5, inplace=False)\n",
              "  (l1): Linear(in_features=128, out_features=1024, bias=True)\n",
              "  (l2): Linear(in_features=1024, out_features=19, bias=True)\n",
              "  (l3): Linear(in_features=64, out_features=1024, bias=True)\n",
              "  (l4): Linear(in_features=1024, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "QLlgGLmwF4Vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_num_correct(preds, labels):\n",
        "  return preds.argmax(dim=1).eq(labels).sum().item()"
      ],
      "metadata": {
        "id": "T3SGPM8bm6CO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = CustomDataset(len(mnist)) # 256 is the batch size\n",
        "#print (len(data))\n",
        "loader = torch.utils.data.DataLoader(data, batch_size=256)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(10):\n",
        "  total_loss_1 = 0\n",
        "  total_correct_1 = 0\n",
        "  total_loss_2 = 0\n",
        "  total_correct_2 = 0\n",
        "  for images, labels, rd, rl in loader: # Get Batch\n",
        "      #print (images.size(), labels.size(), rd.size(), rl.size())\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      rd = rd.to(device)\n",
        "      rl = rl.to(device)\n",
        "\n",
        "      preds1, preds2 = model(images, rd) # Pass Batch of images and one hot encoded random number\n",
        "\n",
        "      loss1 = F.cross_entropy(preds1, labels) # Calculate Loss1\n",
        "      loss2 = F.cross_entropy(preds2, rl) # Calculate Loss2\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss1.backward(retain_graph=True) # Calculate Gradients\n",
        "      loss2.backward(retain_graph=True) # Calculate Gradients\n",
        "\n",
        "      optimizer.step() # Update Weights\n",
        "\n",
        "      total_loss_1 += loss1.item()\n",
        "      total_correct_1 += get_num_correct(preds1, labels)\n",
        "\n",
        "      total_loss_2 += loss2.item()\n",
        "      total_correct_2 += get_num_correct(preds2, rl)\n",
        "\n",
        "  print(\n",
        "      \"epoch:\", epoch, \"\\n\",\n",
        "      \"\\tMNIST Architecture: { \"\n",
        "      #\"total_correct:\", total_correct/len(train_set)*100, \n",
        "      \"accuracy(percentage):\", total_correct_1/len(mnist)*100,\n",
        "      #\"loss:\", total_loss/len(train_loader)\n",
        "      \"loss:\", total_loss_1,\"}\\n\"\n",
        "      \"\\tAddition(MNIST+RAND_NO) Architecture: { \"\n",
        "      #\"total_correct:\", total_correct/len(train_set)*100, \n",
        "      \"accuracy(percentage):\", total_correct_2/len(mnist)*100,\n",
        "      #\"loss:\", total_loss/len(train_loader)\n",
        "      \"loss:\", total_loss_2,\"}\\n\"\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABc9gcm0lLbM",
        "outputId": "c72c6558-fd47-4479-c8e1-612cfd06717d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 \n",
            " \tMNIST Architecture: { accuracy(percentage): 95.61 loss: 34.24793455610052 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 89.66666666666666 loss: 83.53082748688757 }\n",
            "\n",
            "epoch: 1 \n",
            " \tMNIST Architecture: { accuracy(percentage): 98.60166666666666 loss: 11.219361798837781 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 97.99 loss: 17.66577799618244 }\n",
            "\n",
            "epoch: 2 \n",
            " \tMNIST Architecture: { accuracy(percentage): 99.00166666666667 loss: 7.943431606516242 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 98.63666666666666 loss: 11.589891081210226 }\n",
            "\n",
            "epoch: 3 \n",
            " \tMNIST Architecture: { accuracy(percentage): 99.17666666666666 loss: 6.3196261681150645 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 98.78166666666667 loss: 10.008783236611634 }\n",
            "\n",
            "epoch: 4 \n",
            " \tMNIST Architecture: { accuracy(percentage): 99.31666666666666 loss: 5.273220074363053 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 99.03999999999999 loss: 7.834814079687931 }\n",
            "\n",
            "epoch: 5 \n",
            " \tMNIST Architecture: { accuracy(percentage): 99.39 loss: 4.9072123655932955 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 99.065 loss: 7.551553615485318 }\n",
            "\n",
            "epoch: 6 \n",
            " \tMNIST Architecture: { accuracy(percentage): 99.51833333333333 loss: 3.656073286285391 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 99.21666666666667 loss: 6.579159940360114 }\n",
            "\n",
            "epoch: 7 \n",
            " \tMNIST Architecture: { accuracy(percentage): 99.55166666666668 loss: 3.5844144999282435 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 99.3 loss: 5.956117514346261 }\n",
            "\n",
            "epoch: 8 \n",
            " \tMNIST Architecture: { accuracy(percentage): 99.47333333333333 loss: 4.225495214501279 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 99.08833333333334 loss: 7.799525289097801 }\n",
            "\n",
            "epoch: 9 \n",
            " \tMNIST Architecture: { accuracy(percentage): 99.45666666666668 loss: 4.1418998365952575 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 99.10333333333334 loss: 7.4501600245712325 }\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the architecture on data from training set (just for visualization)"
      ],
      "metadata": {
        "id": "CO6RBR6QQ6b5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = CustomDataset(1)\n",
        "for m in data:\n",
        "  grid = torchvision.utils.make_grid(m[0], nrow=10)\n",
        "  plt.figure(figsize=(5,5))\n",
        "  plt.imshow(np.transpose(grid, (1,2,0)))\n",
        "  image = m[0].to(device).unsqueeze(dim=0)\n",
        "  #print (image.shape)\n",
        "  rand_num_oh = m[2].to(device).unsqueeze(dim=0)\n",
        "  #print(rand_num_oh.shape)\n",
        "  out1, out2 = model(image, rand_num_oh)\n",
        "  #print (out_predict)\n",
        "  pred = out1.max(1, keepdim=True)[1] \n",
        "  print(\"\\n\\t MNIST Predicted Label:\", pred.item(), \"\\n\\tActual Label:\", m[1].squeeze(-1), \"\\t\\t\")\n",
        "\n",
        "  #print (\"\\t\\t Added architecture Predicted Label:\", out2.max(1, keepdim=True)[1].item(), \"\\n\\tActual addition value:\", m[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "b_URgaGyRvZv",
        "outputId": "0dae4916-0ada-42b2-c577-82ccf75ce7b9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t MNIST Predicted Label: 2 \n",
            "\tActual Label: tensor(2) \t\t\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}