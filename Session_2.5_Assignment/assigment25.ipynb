{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcBh7+xGSPlSeTPf0gINTK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DimpleB0501/eva8/blob/main/Session_2.5_Assignment/assigment25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST dataset train and test"
      ],
      "metadata": {
        "id": "L5JhFQGxbfxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsHBhPacblK6",
        "outputId": "c6a1208f-6b73-47af-962c-d892e06d1cf9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision # provide access to datasets, models, transforms, utils, etc\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "iOaCUQu-gCE9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Pytorch version:\", torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqBa20zugGQJ",
        "outputId": "05711698-2caa-4239-c5ef-242de23ee3b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pytorch version: 1.13.0+cu116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select GPU mode"
      ],
      "metadata": {
        "id": "iUlzppVygH-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU available\n",
        "if torch.cuda.is_available():\n",
        "  print (\"On GPU\")\n",
        "else :\n",
        "  print (\"No GPU available\")\n",
        "     \n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35ZsFIgSgGqd",
        "outputId": "8ea1b149-14f6-4a67-e39d-9e25090aa72e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a custom dataset"
      ],
      "metadata": {
        "id": "2NFm5u_hj2eO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "E5OqobnXnPQ-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist =  torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform = transforms.Compose([\n",
        "          transforms.ToTensor()\n",
        "    ])\n",
        ")"
      ],
      "metadata": {
        "id": "YRaGNS6zkVy6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One value in dataset"
      ],
      "metadata": {
        "id": "o-sRRlA76-6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(mnist, batch_size = 1, shuffle=True)"
      ],
      "metadata": {
        "id": "Pqu2nE6qwACd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating custom dataset\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    batch = next(iter(train_loader))\n",
        "    self.data = batch[0]\n",
        "    self.label = batch[1]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image = self.data[index]\n",
        "    label = self.label[index]\n",
        "    z = torch.tensor(random.randint(0, 9))\n",
        "    #z_oh = one_hot (z)\n",
        "    #return image, label, z_oh, label+z\n",
        "    return image, label, z, label+z\n",
        "   \n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "myData = MyDataset()\n",
        "\n",
        "for m in myData:\n",
        "  print (\"label:\", m[1])\n",
        "  print (\"Random number generated:\", m[2])\n",
        "  print (\"Addition(randnum+image):\", m[3])\n",
        "  print (\"Image:\")\n",
        "  grid = torchvision.utils.make_grid(m[0], nrow=10)\n",
        "  plt.figure(figsize=(5,5))\n",
        "  plt.imshow(np.transpose(grid, (1,2,0)))\n",
        "\n",
        "#print (\"here\", len(myData))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "xC0Qq4sDxf-s",
        "outputId": "339431b6-109c-4cf6-c2bd-b5143c8c3a38"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label: tensor(3)\n",
            "Random number generated: tensor(1)\n",
            "Addition(randnum+image): tensor(4)\n",
            "Image:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom dataset"
      ],
      "metadata": {
        "id": "T6mJN63S7SdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot encoding\n",
        "def one_hot (integer):\n",
        "  rand_number = torch.zeros(28, 28)\n",
        "  rand_number[:,] =1\n",
        "  one_hot=torch.zeros(28)\n",
        "  one_hot[integer]=1\n",
        "  rand_number = rand_number * one_hot\n",
        "  #print (rand_number)\n",
        "  #print (rand_number.shape)\n",
        "  rand_number = rand_number.unsqueeze(dim=0)\n",
        "  return rand_number"
      ],
      "metadata": {
        "id": "5gmfjyChnHgG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_label(label):\n",
        "  rand_number = torch.zeros(1, 20)\n",
        "  rand_number[:,] =1\n",
        "  one_hot=torch.zeros(20)\n",
        "  one_hot[label]=1\n",
        "  rand_number = rand_number * one_hot\n",
        "  #print (rand_number)\n",
        "  rand_number = rand_number.squeeze(dim=0)\n",
        "  return rand_number"
      ],
      "metadata": {
        "id": "VkFjsNpvwFUS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, batch_size = 50000):\n",
        "    train_loader = torch.utils.data.DataLoader(mnist, batch_size = batch_size, shuffle=True)\n",
        "    batch = next(iter(train_loader))\n",
        "    self.data = batch[0]\n",
        "    self.label = batch[1]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image = self.data[index]\n",
        "    label = self.label[index]\n",
        "    z = torch.tensor(random.randint(0, 9))\n",
        "    z_oh = one_hot(z)\n",
        "    #label_add = one_hot_label(label+z)\n",
        "    #return image, label, z_oh, label_add\n",
        "    return image, label, z_oh, label+z\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "'''\n",
        "for m in data:\n",
        "  print (\"label:\", m[1])\n",
        "  print (\"Random number generated:\", m[2])\n",
        "  print (\"Addition(randnum+image):\", m[3])\n",
        "  print (\"Image:\")\n",
        "  grid = torchvision.utils.make_grid(m[0], nrow=10)\n",
        "  plt.figure(figsize=(2,2))\n",
        "  plt.imshow(np.transpose(grid, (1,2,0)))\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "akM5_DtX93Sp",
        "outputId": "edfd7890-2707-4c90-b2df-fce704766ec5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfor m in data:\\n  print (\"label:\", m[1])\\n  print (\"Random number generated:\", m[2])\\n  print (\"Addition(randnum+image):\", m[3])\\n  print (\"Image:\")\\n  grid = torchvision.utils.make_grid(m[0], nrow=10)\\n  plt.figure(figsize=(2,2))\\n  plt.imshow(np.transpose(grid, (1,2,0)))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model addition\n"
      ],
      "metadata": {
        "id": "kJYOorjtE1Bv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self,x):\n",
        "        N,_,_,_ = x.size()\n",
        "        return x.view(N,-1)"
      ],
      "metadata": {
        "id": "wwjlE9UZE5Vx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=16,kernel_size=5,stride=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16,out_channels=32,kernel_size=5,stride=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.bn1  = nn.BatchNorm2d(num_features=16)\n",
        "        self.bn2   = nn.BatchNorm2d(num_features=32)\n",
        "        self.bn3   = nn.BatchNorm2d(num_features=64)\n",
        "        self.mp   = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "        self.do   = nn.Dropout2d(p=0.5)\n",
        "        self.l1   =  nn.Linear(128,1024)\n",
        "        self.l2   =  nn.Linear(1024,19)\n",
        "\n",
        "        self.l3 = nn.Linear(64, 1024)\n",
        "        self.l4 = nn.Linear(1024, 10)\n",
        "        \n",
        "    def forward(self, x , y):\n",
        "        x = self.conv_layers1(x)\n",
        "        y = self.conv_layers1(y)\n",
        "        x = self.conv_layers2(x)\n",
        "        y = self.conv_layers2(y)\n",
        "        x = self.conv_layers3(x)\n",
        "        y = self.conv_layers3(y)\n",
        "        N ,_,_,_ = x.size()\n",
        "        x = x.view(N,-1)\n",
        "        #print (\"value_check:\", N)\n",
        "        y = y.view(N,-1)\n",
        "        #z = self.conv_layers2(x + y)\n",
        "        z = torch.cat((x,y),1)\n",
        "        #z = z.view(N,-1)\n",
        "        #print(z.size())\n",
        "        z = self.l1(z)\n",
        "        z = self.relu(z)\n",
        "        z = self.l2(z)\n",
        "\n",
        "        x = self.l3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.l4(x)\n",
        "        return x, z\n",
        "    \n",
        "    def conv_layers1(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.mp(x)\n",
        "        return x\n",
        "    \n",
        "    def conv_layers2(self, x):\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.mp(x)\n",
        "        return x\n",
        "    \n",
        "    def conv_layers3(self, x):\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.mp(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ZGtqdjsYeZJU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-NnwcGMFPeD",
        "outputId": "ca3484a1-5dfc-4824-8d4d-998f53fdc904"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (do): Dropout2d(p=0.5, inplace=False)\n",
              "  (l1): Linear(in_features=128, out_features=1024, bias=True)\n",
              "  (l2): Linear(in_features=1024, out_features=19, bias=True)\n",
              "  (l3): Linear(in_features=64, out_features=1024, bias=True)\n",
              "  (l4): Linear(in_features=1024, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "QLlgGLmwF4Vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_num_correct(preds, labels):\n",
        "  return preds.argmax(dim=1).eq(labels).sum().item()"
      ],
      "metadata": {
        "id": "T3SGPM8bm6CO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = CustomDataset(len(mnist)) # 256 is the batch size\n",
        "#print (len(data))\n",
        "loader = torch.utils.data.DataLoader(data, batch_size=256)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(10):\n",
        "  total_loss_1 = 0\n",
        "  total_correct_1 = 0\n",
        "  total_loss_2 = 0\n",
        "  total_correct_2 = 0\n",
        "  for images, labels, rd, rl in loader: # Get Batch\n",
        "      #print (images.size(), labels.size(), rd.size(), rl.size())\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      rd = rd.to(device)\n",
        "      rl = rl.to(device)\n",
        "\n",
        "      preds1, preds2 = model(images, rd) # Pass Batch of images and one hot encoded random number\n",
        "\n",
        "      loss1 = F.cross_entropy(preds1, labels) # Calculate Loss1\n",
        "      loss2 = F.cross_entropy(preds2, rl) # Calculate Loss2\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss1.backward(retain_graph=True) # Calculate Gradients\n",
        "      loss2.backward(retain_graph=True) # Calculate Gradients\n",
        "\n",
        "      optimizer.step() # Update Weights\n",
        "\n",
        "      total_loss_1 += loss1.item()\n",
        "      total_correct_1 += get_num_correct(preds1, labels)\n",
        "\n",
        "      total_loss_2 += loss2.item()\n",
        "      total_correct_2 += get_num_correct(preds2, rl)\n",
        "\n",
        "  print(\n",
        "      \"epoch:\", epoch, \"\\n\",\n",
        "      \"\\tMNIST Architecture: { \"\n",
        "      #\"total_correct:\", total_correct/len(train_set)*100, \n",
        "      \"accuracy(percentage):\", total_correct_1/len(mnist)*100,\n",
        "      #\"loss:\", total_loss/len(train_loader)\n",
        "      \"loss:\", total_loss_1,\"}\\n\"\n",
        "      \"\\tAddition(MNIST+RAND_NO) Architecture: { \"\n",
        "      #\"total_correct:\", total_correct/len(train_set)*100, \n",
        "      \"accuracy(percentage):\", total_correct_2/len(mnist)*100,\n",
        "      #\"loss:\", total_loss/len(train_loader)\n",
        "      \"loss:\", total_loss_2,\"}\\n\"\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABc9gcm0lLbM",
        "outputId": "21c3c011-c7c9-49a8-e826-835cca5a50c5"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 \n",
            " \tMNIST Architecture: { accuracy(percentage): 95.08833333333332 loss: 38.37686620466411 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 88.58166666666666 loss: 86.77631059288979 }\n",
            "\n",
            "epoch: 1 \n",
            " \tMNIST Architecture: { accuracy(percentage): 98.59333333333333 loss: 11.224147853907198 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 97.98833333333333 loss: 17.49341095611453 }\n",
            "\n",
            "epoch: 2 \n",
            " \tMNIST Architecture: { accuracy(percentage): 98.92 loss: 8.467151714023203 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 98.15166666666667 loss: 15.796965256799012 }\n",
            "\n",
            "epoch: 3 \n",
            " \tMNIST Architecture: { accuracy(percentage): 99.00666666666666 loss: 7.938455551629886 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 98.47333333333333 loss: 12.691157527733594 }\n",
            "\n",
            "epoch: 4 \n",
            " \tMNIST Architecture: { accuracy(percentage): 99.27 loss: 5.56925131555181 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 99.02833333333334 loss: 8.645959311164916 }\n",
            "\n",
            "epoch: 5 \n",
            " \tMNIST Architecture: { accuracy(percentage): 99.44833333333334 loss: 4.5161246419884264 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 99.16333333333334 loss: 6.57977039902471 }\n",
            "\n",
            "epoch: 6 \n",
            " \tMNIST Architecture: { accuracy(percentage): 99.5 loss: 3.8290257181506604 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 99.29 loss: 6.07763960189186 }\n",
            "\n",
            "epoch: 7 \n",
            " \tMNIST Architecture: { accuracy(percentage): 99.445 loss: 4.084044247487327 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 99.23333333333333 loss: 6.112494753790088 }\n",
            "\n",
            "epoch: 8 \n",
            " \tMNIST Architecture: { accuracy(percentage): 99.52666666666666 loss: 3.7339959355886094 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 99.25333333333334 loss: 6.295113083964679 }\n",
            "\n",
            "epoch: 9 \n",
            " \tMNIST Architecture: { accuracy(percentage): 99.59166666666667 loss: 3.2240350709616905 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 99.38333333333334 loss: 5.310669594211504 }\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing the architecture on data from training set (just for visualization)"
      ],
      "metadata": {
        "id": "CO6RBR6QQ6b5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = CustomDataset(1)\n",
        "for m in data:\n",
        "  grid = torchvision.utils.make_grid(m[0], nrow=10)\n",
        "  plt.figure(figsize=(5,5))\n",
        "  plt.imshow(np.transpose(grid, (1,2,0)))\n",
        "  image = m[0].to(device).unsqueeze(dim=0)\n",
        "  #print (image.shape)\n",
        "  rand_num_oh = m[2].to(device).unsqueeze(dim=0)\n",
        "  #print(rand_num_oh.shape)\n",
        "  out1, out2 = model(image, rand_num_oh)\n",
        "  #print (out_predict)\n",
        "  pred = out1.max(1, keepdim=True)[1] \n",
        "  print(\"\\n\\t MNIST Predicted Label:\", pred.item(), \"\\t\\t\\t Added architecture Predicted Label:\", out2.max(1, keepdim=True)[1].item(), \"\\n\\tActual Label:\", m[1].squeeze(-1), \"\\t\\t\\t\\t Actual addition value:\", m[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "b_URgaGyRvZv",
        "outputId": "ebaaa859-20c3-448a-c8b5-5ccf859b0359"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\t MNIST Predicted Label: 2 \t\t\t Added architecture Predicted Label: 10 \n",
            "\tActual Label: tensor(2) \t\t\t\t Actual addition value: tensor(8)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}