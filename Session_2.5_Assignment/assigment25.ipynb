{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP6TceQDwgY5B6fYqIE21Qo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DimpleB0501/eva8/blob/main/Session_2.5_Assignment/assigment25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST dataset train and test"
      ],
      "metadata": {
        "id": "L5JhFQGxbfxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsHBhPacblK6",
        "outputId": "9570acdf-6842-497d-e624-4d43882f65a1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision # provide access to datasets, models, transforms, utils, etc\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "iOaCUQu-gCE9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Pytorch version:\", torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqBa20zugGQJ",
        "outputId": "aa9b4d0e-dd85-4f60-f3ee-b67fb7aa3f63"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pytorch version: 1.13.0+cu116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select GPU mode"
      ],
      "metadata": {
        "id": "iUlzppVygH-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU available\n",
        "if torch.cuda.is_available():\n",
        "  print (\"On GPU\")\n",
        "else :\n",
        "  print (\"No GPU available\")\n",
        "     \n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35ZsFIgSgGqd",
        "outputId": "e6c68fa7-1829-470e-f6a4-64d8a1550d2d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a custom dataset"
      ],
      "metadata": {
        "id": "2NFm5u_hj2eO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "E5OqobnXnPQ-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist =  torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform = transforms.Compose([\n",
        "          transforms.ToTensor()\n",
        "    ])\n",
        ")"
      ],
      "metadata": {
        "id": "YRaGNS6zkVy6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One value in dataset"
      ],
      "metadata": {
        "id": "o-sRRlA76-6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(mnist, batch_size = 1, shuffle=True)"
      ],
      "metadata": {
        "id": "Pqu2nE6qwACd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating custom dataset\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    batch = next(iter(train_loader))\n",
        "    self.data = batch[0]\n",
        "    self.label = batch[1]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image = self.data[index]\n",
        "    label = self.label[index]\n",
        "    z = torch.tensor(random.randint(0, 9))\n",
        "    #z_oh = one_hot (z)\n",
        "    #return image, label, z_oh, label+z\n",
        "    return image, label, z, label+z\n",
        "   \n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "myData = MyDataset()\n",
        "\n",
        "for m in myData:\n",
        "  print (\"label:\", m[1])\n",
        "  print (\"Random number generated:\", m[2])\n",
        "  print (\"Addition(randnum+image):\", m[3])\n",
        "  print (\"Image:\")\n",
        "  grid = torchvision.utils.make_grid(m[0], nrow=10)\n",
        "  plt.figure(figsize=(5,5))\n",
        "  plt.imshow(np.transpose(grid, (1,2,0)))\n",
        "\n",
        "#print (\"here\", len(myData))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "xC0Qq4sDxf-s",
        "outputId": "472b9b95-00a8-41ce-cb2f-413d0e05d2b8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label: tensor(5)\n",
            "Random number generated: tensor(0)\n",
            "Addition(randnum+image): tensor(5)\n",
            "Image:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom dataset"
      ],
      "metadata": {
        "id": "T6mJN63S7SdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot encoding\n",
        "def one_hot (integer):\n",
        "  rand_number = torch.zeros(28, 28)\n",
        "  rand_number[:,] =1\n",
        "  one_hot=torch.zeros(28)\n",
        "  one_hot[integer]=1\n",
        "  rand_number = rand_number * one_hot\n",
        "  #print (rand_number)\n",
        "  #print (rand_number.shape)\n",
        "  rand_number = rand_number.unsqueeze(dim=0)\n",
        "  return rand_number"
      ],
      "metadata": {
        "id": "5gmfjyChnHgG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_label(label):\n",
        "  rand_number = torch.zeros(1, 20)\n",
        "  rand_number[:,] =1\n",
        "  one_hot=torch.zeros(20)\n",
        "  one_hot[label]=1\n",
        "  rand_number = rand_number * one_hot\n",
        "  #print (rand_number)\n",
        "  rand_number = rand_number.squeeze(dim=0)\n",
        "  return rand_number"
      ],
      "metadata": {
        "id": "VkFjsNpvwFUS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, batch_size = 50000):\n",
        "    train_loader = torch.utils.data.DataLoader(mnist, batch_size = batch_size, shuffle=True)\n",
        "    batch = next(iter(train_loader))\n",
        "    self.data = batch[0]\n",
        "    self.label = batch[1]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image = self.data[index]\n",
        "    label = self.label[index]\n",
        "    z = torch.tensor(random.randint(0, 9))\n",
        "    z_oh = one_hot(z)\n",
        "    #label_add = one_hot_label(label+z)\n",
        "    #return image, label, z_oh, label_add\n",
        "    return image, label, z_oh, label+z\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "'''\n",
        "for m in data:\n",
        "  print (\"label:\", m[1])\n",
        "  print (\"Random number generated:\", m[2])\n",
        "  print (\"Addition(randnum+image):\", m[3])\n",
        "  print (\"Image:\")\n",
        "  grid = torchvision.utils.make_grid(m[0], nrow=10)\n",
        "  plt.figure(figsize=(2,2))\n",
        "  plt.imshow(np.transpose(grid, (1,2,0)))\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "akM5_DtX93Sp",
        "outputId": "85ff3c0f-c0ba-46e9-c037-1c7881587925"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfor m in data:\\n  print (\"label:\", m[1])\\n  print (\"Random number generated:\", m[2])\\n  print (\"Addition(randnum+image):\", m[3])\\n  print (\"Image:\")\\n  grid = torchvision.utils.make_grid(m[0], nrow=10)\\n  plt.figure(figsize=(2,2))\\n  plt.imshow(np.transpose(grid, (1,2,0)))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model addition\n"
      ],
      "metadata": {
        "id": "kJYOorjtE1Bv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self,x):\n",
        "        N,_,_,_ = x.size()\n",
        "        return x.view(N,-1)"
      ],
      "metadata": {
        "id": "wwjlE9UZE5Vx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=16,kernel_size=5,stride=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=16,out_channels=32,kernel_size=5,stride=1)\n",
        "        self.conv3 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=3,stride=1)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.bn1  = nn.BatchNorm2d(num_features=16)\n",
        "        self.bn2   = nn.BatchNorm2d(num_features=32)\n",
        "        self.bn3   = nn.BatchNorm2d(num_features=64)\n",
        "        self.mp   = nn.MaxPool2d(kernel_size=2,stride=2)\n",
        "        self.do   = nn.Dropout2d(p=0.5)\n",
        "        self.l1   =  nn.Linear(128,1024)\n",
        "        self.l2   =  nn.Linear(1024,19)\n",
        "\n",
        "        self.l3 = nn.Linear(64, 1024)\n",
        "        self.l4 = nn.Linear(1024, 10)\n",
        "        \n",
        "    def forward(self, x , y):\n",
        "        x = self.conv_layers1(x)\n",
        "        y = self.conv_layers1(y)\n",
        "        x = self.conv_layers2(x)\n",
        "        y = self.conv_layers2(y)\n",
        "        x = self.conv_layers3(x)\n",
        "        y = self.conv_layers3(y)\n",
        "        N ,_,_,_ = x.size()\n",
        "        x = x.view(N,-1)\n",
        "        #print (\"value_check:\", N)\n",
        "        y = y.view(N,-1)\n",
        "        #z = self.conv_layers2(x + y)\n",
        "        z = torch.cat((x,y),1)\n",
        "        #z = z.view(N,-1)\n",
        "        #print(z.size())\n",
        "        z = self.l1(z)\n",
        "        z = self.relu(z)\n",
        "        z = self.l2(z)\n",
        "\n",
        "        x = self.l3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.l4(x)\n",
        "        return x, z\n",
        "    \n",
        "    def conv_layers1(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.mp(x)\n",
        "        return x\n",
        "    \n",
        "    def conv_layers2(self, x):\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.mp(x)\n",
        "        return x\n",
        "    \n",
        "    def conv_layers3(self, x):\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.mp(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "ZGtqdjsYeZJU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-NnwcGMFPeD",
        "outputId": "b5f853c1-c6df-4155-be28-3c36d86c100f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (do): Dropout2d(p=0.5, inplace=False)\n",
              "  (l1): Linear(in_features=128, out_features=1024, bias=True)\n",
              "  (l2): Linear(in_features=1024, out_features=19, bias=True)\n",
              "  (l3): Linear(in_features=64, out_features=1024, bias=True)\n",
              "  (l4): Linear(in_features=1024, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "QLlgGLmwF4Vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_num_correct(preds, labels):\n",
        "  return preds.argmax(dim=1).eq(labels).sum().item()"
      ],
      "metadata": {
        "id": "T3SGPM8bm6CO"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = CustomDataset(len(mnist)) # 256 is the batch size\n",
        "#print (len(data))\n",
        "loader = torch.utils.data.DataLoader(data, batch_size=256)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(10):\n",
        "  total_loss_1 = 0\n",
        "  total_correct_1 = 0\n",
        "  total_loss_2 = 0\n",
        "  total_correct_2 = 0\n",
        "  for images, labels, rd, rl in loader: # Get Batch\n",
        "      #print (images.size(), labels.size(), rd.size(), rl.size())\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      rd = rd.to(device)\n",
        "      rl = rl.to(device)\n",
        "\n",
        "      preds1, preds2 = model(images, rd) # Pass Batch of images and one hot encoded random number\n",
        "\n",
        "      loss1 = F.cross_entropy(preds1, labels) # Calculate Loss1\n",
        "      loss2 = F.cross_entropy(preds2, rl) # Calculate Loss2\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss1.backward(retain_graph=True) # Calculate Gradients\n",
        "      loss2.backward(retain_graph=True) # Calculate Gradients\n",
        "\n",
        "      optimizer.step() # Update Weights\n",
        "\n",
        "      total_loss_1 += loss1.item()\n",
        "      total_correct_1 += get_num_correct(preds1, labels)\n",
        "\n",
        "      total_loss_2 += loss2.item()\n",
        "      total_correct_2 += get_num_correct(preds2, rl)\n",
        "\n",
        "  print(\n",
        "      \"epoch:\", epoch, \"\\n\",\n",
        "      \"\\tMNIST-LENET Architecture: { \"\n",
        "      #\"total_correct:\", total_correct/len(train_set)*100, \n",
        "      \"accuracy(percentage):\", total_correct_1/len(mnist)*100,\n",
        "      #\"loss:\", total_loss/len(train_loader)\n",
        "      \"loss:\", total_loss_1,\"}\\n\"\n",
        "      \"\\tAddition(MNIST+RAND_NO) Architecture: { \"\n",
        "      #\"total_correct:\", total_correct/len(train_set)*100, \n",
        "      \"accuracy(percentage):\", total_correct_2/len(mnist)*100,\n",
        "      #\"loss:\", total_loss/len(train_loader)\n",
        "      \"loss:\", total_loss_2,\"}\\n\"\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABc9gcm0lLbM",
        "outputId": "24451700-d2cd-46d4-c097-b06cb9586dc6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 \n",
            " \tMNIST-LENET Architecture: { accuracy(percentage): 95.14666666666668 loss: 37.67370465118438 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 87.785 loss: 94.13048843294382 }\n",
            "\n",
            "epoch: 1 \n",
            " \tMNIST-LENET Architecture: { accuracy(percentage): 98.63 loss: 10.8749037864618 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 98.09833333333333 loss: 16.405367070809007 }\n",
            "\n",
            "epoch: 2 \n",
            " \tMNIST-LENET Architecture: { accuracy(percentage): 98.91666666666666 loss: 8.377613559830934 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 98.53166666666667 loss: 12.728949782904238 }\n",
            "\n",
            "epoch: 3 \n",
            " \tMNIST-LENET Architecture: { accuracy(percentage): 99.19 loss: 6.396785899414681 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 98.82333333333332 loss: 9.882947911974043 }\n",
            "\n",
            "epoch: 4 \n",
            " \tMNIST-LENET Architecture: { accuracy(percentage): 99.31833333333333 loss: 5.178995206253603 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 99.02499999999999 loss: 8.092244151979685 }\n",
            "\n",
            "epoch: 5 \n",
            " \tMNIST-LENET Architecture: { accuracy(percentage): 99.47333333333333 loss: 4.154774336289847 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 99.14833333333334 loss: 7.098114724911284 }\n",
            "\n",
            "epoch: 6 \n",
            " \tMNIST-LENET Architecture: { accuracy(percentage): 99.59333333333333 loss: 3.3682096823504253 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 99.34333333333333 loss: 5.337699698924553 }\n",
            "\n",
            "epoch: 7 \n",
            " \tMNIST-LENET Architecture: { accuracy(percentage): 99.49833333333333 loss: 3.784283522894839 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 99.30166666666666 loss: 5.6723648156330455 }\n",
            "\n",
            "epoch: 8 \n",
            " \tMNIST-LENET Architecture: { accuracy(percentage): 99.63 loss: 3.033821078352048 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 99.41499999999999 loss: 4.824314412428066 }\n",
            "\n",
            "epoch: 9 \n",
            " \tMNIST-LENET Architecture: { accuracy(percentage): 99.53 loss: 3.6177552277804352 }\n",
            "\tAddition(MNIST+RAND_NO) Architecture: { accuracy(percentage): 99.34166666666667 loss: 5.564803821442183 }\n",
            "\n"
          ]
        }
      ]
    }
  ]
}