{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOF3HfjbcL/zWpPpwClruFV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DimpleB0501/eva8/blob/main/Session_2.5_Assignment/assigment2.5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST dataset train and test"
      ],
      "metadata": {
        "id": "L5JhFQGxbfxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsHBhPacblK6",
        "outputId": "34ff0361-1cef-4327-d33d-bfe8e65a2db4"
      },
      "execution_count": 361,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision # provide access to datasets, models, transforms, utils, etc\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "iOaCUQu-gCE9"
      },
      "execution_count": 362,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"Pytorch version:\", torch.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqBa20zugGQJ",
        "outputId": "18c98cad-98cf-45ff-be87-4813ddf2b250"
      },
      "execution_count": 363,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pytorch version: 1.13.0+cu116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select GPU mode"
      ],
      "metadata": {
        "id": "iUlzppVygH-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU available\n",
        "if torch.cuda.is_available():\n",
        "  print (\"On GPU\")\n",
        "else :\n",
        "  print (\"No GPU available\")\n",
        "     \n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35ZsFIgSgGqd",
        "outputId": "fd9ac174-d93e-4c82-925d-9199b34e2354"
      },
      "execution_count": 364,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a custom dataset"
      ],
      "metadata": {
        "id": "2NFm5u_hj2eO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "E5OqobnXnPQ-"
      },
      "execution_count": 365,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist =  torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform = transforms.Compose([\n",
        "          transforms.ToTensor()\n",
        "    ])\n",
        ")"
      ],
      "metadata": {
        "id": "YRaGNS6zkVy6"
      },
      "execution_count": 366,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One value in dataset"
      ],
      "metadata": {
        "id": "o-sRRlA76-6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(mnist, batch_size = 1, shuffle=True)"
      ],
      "metadata": {
        "id": "Pqu2nE6qwACd"
      },
      "execution_count": 367,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating custom dataset\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    batch = next(iter(train_loader))\n",
        "    self.data = batch[0]\n",
        "    self.label = batch[1]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image = self.data[index]\n",
        "    label = self.label[index]\n",
        "    z = torch.tensor(random.randint(0, 9))\n",
        "    return image, label, z, label+z\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "myData = MyDataset()\n",
        "\n",
        "for m in myData:\n",
        "  print (\"label:\", m[1])\n",
        "  print (\"Random number generated:\", m[2])\n",
        "  print (\"Addition(randnum+image):\", m[3])\n",
        "  print (\"Image:\")\n",
        "  grid = torchvision.utils.make_grid(m[0], nrow=10)\n",
        "  plt.figure(figsize=(5,5))\n",
        "  plt.imshow(np.transpose(grid, (1,2,0)))\n",
        "\n",
        "#print (\"here\", len(myData))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "xC0Qq4sDxf-s",
        "outputId": "9b81d784-f410-4a0c-a964-9171ec2ff0d6"
      },
      "execution_count": 368,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label: tensor(6)\n",
            "Random number generated: tensor(8)\n",
            "Addition(randnum+image): tensor(14)\n",
            "Image:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Custom dataset"
      ],
      "metadata": {
        "id": "T6mJN63S7SdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, batch_size = 50000):\n",
        "    train_loader = torch.utils.data.DataLoader(mnist, batch_size = batch_size, shuffle=True)\n",
        "    batch = next(iter(train_loader))\n",
        "    self.data = batch[0]\n",
        "    self.label = batch[1]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image = self.data[index]\n",
        "    label = self.label[index]\n",
        "    z = torch.tensor(random.randint(0, 9))\n",
        "    return image, label, z, label+z\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "'''\n",
        "for m in data:\n",
        "  print (\"label:\", m[1])\n",
        "  print (\"Random number generated:\", m[2])\n",
        "  print (\"Addition(randnum+image):\", m[3])\n",
        "  print (\"Image:\")\n",
        "  grid = torchvision.utils.make_grid(m[0], nrow=10)\n",
        "  plt.figure(figsize=(2,2))\n",
        "  plt.imshow(np.transpose(grid, (1,2,0)))\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "akM5_DtX93Sp",
        "outputId": "f12dd1ed-1acd-4771-dd74-f51b434c560c"
      },
      "execution_count": 369,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfor m in data:\\n  print (\"label:\", m[1])\\n  print (\"Random number generated:\", m[2])\\n  print (\"Addition(randnum+image):\", m[3])\\n  print (\"Image:\")\\n  grid = torchvision.utils.make_grid(m[0], nrow=10)\\n  plt.figure(figsize=(2,2))\\n  plt.imshow(np.transpose(grid, (1,2,0)))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 369
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a model"
      ],
      "metadata": {
        "id": "EOAJH-7yhmkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "6Da9Luvil2PF"
      },
      "execution_count": 370,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LeNet(torch.nn.Module):\n",
        "     \n",
        "  def __init__(self):   \n",
        "        super(LeNet, self).__init__()\n",
        "        # Convolution (In LeNet, 32x32 images are given as input. Hence padding of 2 is done below)\n",
        "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2, bias=True)\n",
        "        # Max-pooling\n",
        "        self.max_pool_1 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "        # Convolution\n",
        "        self.conv2 = torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0, bias=True)\n",
        "        # Max-pooling\n",
        "        self.max_pool_2 = torch.nn.MaxPool2d(kernel_size=2)\n",
        "        # Fully connected layer\n",
        "        self.fc1 = torch.nn.Linear(16*5*5, 120)   # convert matrix with 16*5*5 (= 400) features to a matrix of 120 features (columns)\n",
        "        self.fc2 = torch.nn.Linear(120, 84)       # convert matrix with 120 features to a matrix of 84 features (columns)\n",
        "        self.fc3 = torch.nn.Linear(84, 10)        # convert matrix with 84 features to a matrix of 10 features (columns)\n",
        "        \n",
        "  def forward(self, out):\n",
        "        # convolve, then perform ReLU non-linearity\n",
        "        out = torch.nn.functional.relu(self.conv1(out))  \n",
        "        # max-pooling with 2x2 grid\n",
        "        out = self.max_pool_1(out)\n",
        "        # convolve, then perform ReLU non-linearity\n",
        "        out = torch.nn.functional.relu(self.conv2(out))\n",
        "        # max-pooling with 2x2 grid\n",
        "        out = self.max_pool_2(out)\n",
        "        # first flatten 'max_pool_2_out' to contain 16*5*5 columns\n",
        "        # read through https://stackoverflow.com/a/42482819/7551231\n",
        "        out = out.view(-1, 16*5*5)\n",
        "        # FC-1, then perform ReLU non-linearity\n",
        "        out = torch.nn.functional.relu(self.fc1(out))\n",
        "        # FC-2, then perform ReLU non-linearity\n",
        "        out = torch.nn.functional.relu(self.fc2(out))\n",
        "        # FC-3\n",
        "        out = self.fc3(out)\n",
        "        \n",
        "        return out"
      ],
      "metadata": {
        "id": "xKt_WWQHh54q"
      },
      "execution_count": 371,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LeNet()\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_KhMEJBiWCQ",
        "outputId": "5f653ffc-3a9d-4ceb-ba10-18ec749692d4"
      },
      "execution_count": 372,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LeNet(\n",
              "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "  (max_pool_1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (max_pool_2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 372
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the model"
      ],
      "metadata": {
        "id": "kdnKTFoEif4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_num_correct(preds, labels):\n",
        "  return preds.argmax(dim=1).eq(labels).sum().item()"
      ],
      "metadata": {
        "id": "T3SGPM8bm6CO"
      },
      "execution_count": 373,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = CustomDataset(len(mnist)) # 256 is the batch size\n",
        "#print (len(data))\n",
        "loader = torch.utils.data.DataLoader(data, batch_size=500)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(10):\n",
        "  total_loss = 0\n",
        "  total_correct = 0\n",
        "  for images, labels, rd, rl in loader: # Get Batch\n",
        "      #print (images.size(), labels.size())\n",
        "      images = images.to(device)\n",
        "      labels = labels.to(device)\n",
        "      preds = model(images) # Pass Batch\n",
        "      loss = F.cross_entropy(preds, labels) # Calculate Loss\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward() # Calculate Gradients\n",
        "      optimizer.step() # Update Weights\n",
        "\n",
        "      total_loss += loss.item()\n",
        "      total_correct += get_num_correct(preds, labels)\n",
        "\n",
        "  print(\n",
        "      \"epoch:\", epoch, \n",
        "      #\"total_correct:\", total_correct/len(train_set)*100, \n",
        "      \"accuracy(percentage):\", total_correct/len(mnist)*100,\n",
        "      #\"loss:\", total_loss/len(train_loader)\n",
        "      \"loss:\", total_loss,\n",
        "  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABc9gcm0lLbM",
        "outputId": "115e3322-2c86-4f70-d9ed-8d7b291cc51b"
      },
      "execution_count": 374,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000\n",
            "epoch: 0 accuracy(percentage): 87.65166666666667 loss: 45.02319601178169\n",
            "epoch: 1 accuracy(percentage): 97.84666666666666 loss: 8.30497346445918\n",
            "epoch: 2 accuracy(percentage): 98.58333333333333 loss: 5.609492338262498\n",
            "epoch: 3 accuracy(percentage): 98.86500000000001 loss: 4.5363947679288685\n",
            "epoch: 4 accuracy(percentage): 98.97833333333334 loss: 3.8929911381565034\n",
            "epoch: 5 accuracy(percentage): 99.13499999999999 loss: 3.14921368425712\n",
            "epoch: 6 accuracy(percentage): 99.20333333333333 loss: 2.9940450116991997\n",
            "epoch: 7 accuracy(percentage): 99.16666666666667 loss: 3.192367531824857\n",
            "epoch: 8 accuracy(percentage): 99.245 loss: 2.802656739251688\n",
            "epoch: 9 accuracy(percentage): 99.33999999999999 loss: 2.541642345720902\n"
          ]
        }
      ]
    }
  ]
}